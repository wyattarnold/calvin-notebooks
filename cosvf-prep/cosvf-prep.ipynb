{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline data for COSVF in CALVIN\n",
    "\n",
    "This script prepares files necessary to instatiate a Carryover Storage Value Function (COSVF) annual limited foresight model of CALVIN. The links file is the export for the first water year (1922) with debug links added from Calvin Network tools.\n",
    "\n",
    "1. ``links.csv``: \n",
    "\n",
    "\n",
    "    Network for the first water year in the period of analysis.\n",
    "  \n",
    "    CSV file with column headers: ``i,j,k,cost,amplitude,lower_bound,upper_bound``\n",
    "\n",
    "2. ``cosvf-params.csv`` \n",
    "    \n",
    "    A table of minimum and maximum marginal cost penalties for quadratic carryover penalty curves on surface water reservoirs and linear penalties on groundwater reservoirs. **The values are not optimized. They are just stand-in values to be replaced by the evolutionary optimization run.**\n",
    "\n",
    "    CSV file with column headers: ``r,param,value``\n",
    "\n",
    "3.  ``r-dict.json``: \n",
    "    \n",
    "    A dictionary of reservoirs in the network with penalty properties. \n",
    "\n",
    "    Type 2 (linear penalty) reservoirs must be ordered prior to the Type 1 (quadratic) reservoirs. This is a limitation of imposed by the evolutionary algorithm search of the parameters. For each reservoir with an EOP penalty, an index attribute ``cosvf_param_index`` points to the row-index (pythonic zero-indexed) of the list of reservoirs in ``cosvf-params.csv``.\n",
    "\n",
    "    Dictionary structure:\n",
    "\n",
    "        {\"<reservoir id (e.g. SR_DNP)>\":\n",
    "        \n",
    "            {\n",
    "              \"eop_init\": \"(float) initial (October 1) storage level\",\n",
    "              \n",
    "              \"lb\": \"(float) minimum (end-of-September) storage level\",\n",
    "              \n",
    "              \"ub\": \"(float) maximum (end-of-September) carryover capactiy\",\n",
    "              \n",
    "              \"type\": \"(int) 0:none; 1:quadratic; or 2:linear\",\n",
    "              \n",
    "              \"cosvf_param_index\": \"(list) index to cosvf_params.csv row (pythonic zero-indexed)\",\n",
    "              \n",
    "              \"k_count\": \"(int) number of piecewise links to fit for quadratic COSVF\",\n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "4.  ``inflows.csv``: \n",
    "    \n",
    "    External inflows for every monthly time step over the period of analysis to run. \n",
    "\n",
    "    CSV file with column headers ``date, j, flow_taf``\n",
    "\n",
    "5.  ``variable-constraints.csv``: \n",
    "    \n",
    "    Links that have variable year-to-year upper and/or lower bounds.\n",
    "\n",
    "    CSV file with column headers ``date,i,j,k,lower_bound,upper_bound``\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pyVIN\n",
    "calvin_dir = os.path.abspath('../../calvin')\n",
    "if str(calvin_dir)!=sys.path:\n",
    "    sys.path.append(calvin_dir)\n",
    "from calvin import CALVIN, cosvfea\n",
    "from calvin import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect forsight model directory\n",
    "pf_dir = '../../calvin/my-models/calvin-pf'\n",
    "\n",
    "#limited forsight model directory\n",
    "lf_dir = '../../calvin/my-models/calvin-lf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %% load perfect foresight links\n",
    "pf_links = pd.read_csv(os.path.join(pf_dir,'links82yr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove debug nodes\n",
    "pf_links = pf_links.loc[\n",
    "    (~pf_links.i.str.contains('DBUG')) & (~pf_links.j.str.contains('DBUG'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for edges (w/o dates)\n",
    "pf_links.insert(0, 'edge', \n",
    "    value=pf_links.i.str.split('.').str[0]+'_'+pf_links.j.str.split('.').str[0])\n",
    "pf_links.insert(1,'i_node',\n",
    "    value=pf_links.i.map(lambda x: x.split('.')[0]))\n",
    "pf_links.insert(2,'j_node',\n",
    "    value=pf_links.j.map(lambda x: x.split('.')[0]))\n",
    "pf_links.insert(0, 'year',\n",
    "    value=pd.DatetimeIndex(pf_links.i.str.split('.').str[1]).year)\n",
    "pf_links.insert(1, 'month',\n",
    "    value=pd.DatetimeIndex(pf_links.i.str.split('.').str[1]).month)\n",
    "pf_links.insert(0, 'date',\n",
    "    value=pd.DatetimeIndex(pf_links.i.str.split('.').str[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Inflows\n",
    "# Extract monthly inflows to csv\n",
    "# load inflows \n",
    "inflow_qwry = pf_links.loc[(pf_links.i.str.contains('INFLOW'))]\n",
    "# split j to node and date\n",
    "inflows = inflow_qwry['j'].str.split('.',expand=True)\n",
    "inflows.columns = ['j','date']\n",
    "inflows['date'] = pd.DatetimeIndex(inflows['date'])\n",
    "inflows.set_index('date',inplace=True)\n",
    "# get inflow values\n",
    "inflows.insert(1,'flow_taf', value = inflow_qwry['lower_bound'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  save out inflows output\n",
    "inflows.to_csv(os.path.join(lf_dir,'inflows.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Variable Constraints\n",
    "# Query out upper and lower bounds that change from year to year and export to csv\n",
    "def get_variable_range(links,column):\n",
    "    variable_links = links.groupby(\n",
    "        ['edge','month','k'])[column].max().subtract(\n",
    "        links.groupby(['edge','month','k'])[column].min())\n",
    "    return(pd.DataFrame(variable_links.iloc[np.where(variable_links>0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_links = pf_links.loc[\n",
    "    (~pf_links.i.str.contains('INFLOW')) &\n",
    "    (~pf_links.i.str.contains('INITIAL')) ]\n",
    "variable_lb = get_variable_range(variable_links,'lower_bound')\n",
    "variable_ub = get_variable_range(variable_links,'upper_bound')\n",
    "variable_min_max = variable_ub.join(variable_lb,how='outer')\n",
    "variable_min_max.head()\n",
    "# query the constraints that were found to vary\n",
    "variable_constraints = pf_links.loc[pf_links['edge'].isin(\n",
    "    variable_min_max.index.get_level_values(0).unique())]\n",
    "# subset storage variable constraints for September only\n",
    "variable_constraints_storages = variable_constraints.loc[\n",
    "    (variable_constraints.i_node==variable_constraints.j_node) &\n",
    "    (variable_constraints.month!=9)]\n",
    "# subset down to the k=0 link\n",
    "variable_constraints_storages_k0 = variable_constraints_storages.loc[variable_constraints_storages.k==0]\n",
    "# get the upper bound on storage variable links\n",
    "variable_constraints_storages_k0ub = variable_constraints_storages.groupby(['i','j'],as_index=False)['upper_bound'].sum()\n",
    "# join to k0 link set and set the actual upper bound \n",
    "variable_constraints_storages_k0 = variable_constraints_storages_k0.merge(variable_constraints_storages_k0ub, on=['i','j'],suffixes=('','_join'))\n",
    "variable_constraints_storages_k0['upper_bound'] = variable_constraints_storages_k0['upper_bound_join'] \n",
    "# set the lower bound on Shasta and Clair Engle to the default constant values\n",
    "variable_constraints_storages_k0.loc[variable_constraints_storages_k0.edge=='SR_SHA_SR_SHA','lower_bound'] = 650\n",
    "variable_constraints_storages_k0.loc[variable_constraints_storages_k0.edge=='SR_CLE_SR_CLE','lower_bound'] = 500\n",
    "# remove storage variable constraints from main variable constraints\n",
    "variable_constraints = variable_constraints.loc[\n",
    "    variable_constraints.i_node!=variable_constraints.j_node]\n",
    "# add back in the variable storage constraints for all other months than September\n",
    "variable_constraints = variable_constraints.append(variable_constraints_storages_k0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% save out variable constraints output\n",
    "variable_constraints = variable_constraints[['date','i','j','k','lower_bound','upper_bound']]\n",
    "variable_constraints.to_csv('variable-constraints.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Reservoirs\n",
    "# List of reservoirs\n",
    "r_list = pf_links.loc[(pf_links.i_node.str.startswith('INITIAL'))].j_node.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reservoirs identified as COSVF canditates (Type 1)\n",
    "r_type1 = ['SR_BER','SR_BUC','SR_BUL','SR_CLE','SR_CLK_INV','SR_CMN','SR_DNP',\n",
    "            'SR_EBMUD','SR_FOL','SR_HTH','SR_ISB','SR_LL_ENR','SR_LVQ','SR_MCR',\n",
    "            'SR_MIL','SR_NHG','SR_NML','SR_ORO','SR_PAR','SR_PNF','SR_RLL_CMB',\n",
    "            'SR_SHA','SR_SNL','SR_SFAGG','SR_GNT','SR_WHI']\n",
    "\n",
    "r_type2 = ['GW_01', 'GW_02', 'GW_03','GW_04', 'GW_05', 'GW_06','GW_07',\n",
    "           'GW_08', 'GW_09', 'GW_10', 'GW_11', 'GW_12', 'GW_13', 'GW_14', 'GW_15',\n",
    "           'GW_16', 'GW_17', 'GW_18', 'GW_19', 'GW_20', 'GW_21',\n",
    "           'GW_AV', 'GW_CH', 'GW_EW', 'GW_IM', 'GW_MJ', 'GW_MWD',\n",
    "           'GW_OW', 'GW_SBV', 'GW_SC', 'GW_SD', 'GW_VC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoir dictionary for calvin limited foresight run\n",
    "r_dict = dict()\n",
    "i = 0\n",
    "for r in r_list:\n",
    "    # initial storage value\n",
    "    initial_storage = pf_links.loc[\n",
    "        (pf_links.i_node=='INITIAL') & (pf_links.j_node==r)].lower_bound\n",
    "    # lower bound on carryover\n",
    "    lb_9 = pf_links.loc[\n",
    "        (pf_links.i_node==r) & (pf_links.j_node==r) & \n",
    "        (pf_links.k==0) & (pf_links.month==9)].lower_bound.min()\n",
    "    # upper bound on carryover from first year\n",
    "    ub_9 = pf_links.loc[\n",
    "        (pf_links.i_node==r) & (pf_links.j_node==r) & \n",
    "        (pf_links.month==9) & (pf_links.year==1922)].upper_bound.sum()\n",
    "    # check COSVF Type 1 to index COSVF param\n",
    "    if r in r_type1:\n",
    "        r_type, cosvf_param_index, k_count, i = 1, [i,i+1], 15, i+2\n",
    "    elif r in r_type2:\n",
    "        r_type, cosvf_param_index, k_count, i = 2, i, 2, i+1\n",
    "    else:\n",
    "        r_type, cosvf_param_index, k_count = 0, None, 1\n",
    "    # add to reservoir dictionary\n",
    "    r_dict[r] = dict([\n",
    "        ('eop_init',initial_storage.values[0]),\n",
    "        ('lb',lb_9),\n",
    "        ('ub',ub_9),\n",
    "        ('type',r_type), \n",
    "        ('cosvf_param_index',cosvf_param_index),\n",
    "        ('k_count',k_count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% save out the reservoir dictionary to json file\n",
    "with open(os.path.join(lf_dir,'r-dict.json'), 'w') as json_file:\n",
    "    json.dump(r_dict, json_file, \n",
    "        sort_keys=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Create default COSVF params\n",
    "param=['pmin','pmax']\n",
    "rtype1_list = list({key: value for key, value in r_dict.items() if value['type'] == 1}.keys())\n",
    "rtype2_list = list({key: value for key, value in r_dict.items() if value['type'] == 2}.keys())\n",
    "pos_r_list = rtype2_list + list(np.repeat(rtype1_list, len(param)))\n",
    "cosvf_pminmax = pd.DataFrame({'value':\n",
    "    list(np.repeat([-1e2], len(rtype2_list))) + list(np.tile([-1e2, -7e2], len(rtype1_list)))})\n",
    "cosvf_pminmax.insert(0,'r',value=pos_r_list)\n",
    "cosvf_pminmax.insert(1,'param',value=list(['p'] * len(rtype2_list) + param * len(rtype1_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% save out default COSVF params\n",
    "cosvf_pminmax.to_csv(os.path.join(lf_dir,'cosvf-params.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('links_default.csv')\n",
    "links.insert(0, 'edge', \n",
    "    value=links.i.str.split('.').str[0]+'_'+links.j.str.split('.').str[0])\n",
    "links.insert(1,'i_node',\n",
    "    value=links.i.map(lambda x: x.split('.')[0]))\n",
    "links.insert(2,'j_node',\n",
    "    value=links.j.map(lambda x: x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_storages = links.loc[(links.i_node==links.j_node) & (links.i_node.isin(r_type1))]\n",
    "# subset down to the k=0 link\n",
    "links_storages_k0 = links_storages.loc[links_storages.k==0]\n",
    "# default all persuasions to -0.02 $/af\n",
    "links_storages_k0['cost'] = -0.02\n",
    "# get the upper bound on storage variable links\n",
    "links_storages_k0ub = links_storages.groupby(['i','j'],as_index=False)['upper_bound'].sum()\n",
    "# join to k0 link set and set the actual upper bound \n",
    "links_storages_k0 = links_storages_k0.merge(links_storages_k0ub, on=['i','j'],suffixes=('','_join'))\n",
    "links_storages_k0['upper_bound'] = links_storages_k0['upper_bound_join'] \n",
    "# set the lower bound on Shasta and Clair Engle to the default constant values\n",
    "links_storages_k0.loc[links_storages_k0.edge=='SR_SHA_SR_SHA','lower_bound'] = 650\n",
    "links_storages_k0.loc[links_storages_k0.edge=='SR_CLE_SR_CLE','lower_bound'] = 500\n",
    "# remove storage variables from main links \n",
    "r_type1_concat = [x+'_'+x for x in r_type1]\n",
    "links = links.loc[~(links.edge.isin(r_type1_concat))]\n",
    "# add back in modified storage links to the main links\n",
    "links = links.append(links_storages_k0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "links[['i','j','k','cost','amplitude','lower_bound','upper_bound']].to_csv('links.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
